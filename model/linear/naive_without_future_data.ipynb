{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for algorithm selection:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:32<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for hyperparameter optimization:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [13:00<00:00,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1-macro: 1.0\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00        70\n",
      "           D       1.00      1.00      1.00        41\n",
      "           H       1.00      1.00      1.00        79\n",
      "\n",
      "    accuracy                           1.00       190\n",
      "   macro avg       1.00      1.00      1.00       190\n",
      "weighted avg       1.00      1.00      1.00       190\n",
      "\n",
      "Matriz de confusión:\n",
      " [[70  0  0]\n",
      " [ 0 41  0]\n",
      " [ 0  0 79]]\n",
      "\n",
      "Cols eliminadas por constantes: ['season', 'max_round', 'is_first_half', 'season_half']\n",
      "Núm. numéricas: 23  | Núm. categóricas: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import naiveautoml\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, log_loss\n",
    "\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"dataset\", \"data\", \"premier_dataset_final.csv\")\n",
    "# --- cargar y ordenar ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "split_idx = len(df) // 2\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "valid_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "TARGET = \"result\"\n",
    "\n",
    "# --- columnas post-partido (fuga directa) ---\n",
    "post_match = [\n",
    "    \"home_goals\",\"away_goals\",\"total_goals\",\"total_ht_goals\",\"BTTS\",\"CleanSheet\",\n",
    "    \"home_elo_after\",\"away_elo_after\",\"elo_change_home\",\"elo_change_away\",\n",
    "    \"HS\",\"AS\",\"HST\",\"AST\",\"total_shots\",\"total_shots_on_target\",\n",
    "    \"shots_per_goal\",\"shots_per_goal_home\",\"shots_per_goal_away\",\n",
    "    \"total_shot_accuracy\",\"total_shot_accuracy_home\",\"total_shot_accuracy_away\",\n",
    "    \"shot_conversion\",\"shot_conversion_home\",\"shot_conversion_away\",\n",
    "    \"shots_on_target_diff\"\n",
    "]\n",
    "\n",
    "# --- columnas de mercado (pre-partido pero muy fuertes) ---\n",
    "market_cols = [c for c in df.columns if any(k in c.lower() for k in [\n",
    "    \"odd_\", \"p_home\", \"p_draw\", \"p_away\", \"overround\", \"fair\",\n",
    "    \"avgh\",\"avgd\",\"avga\", \"avg>2.5\", \"avg<2.5\", \"over_\", \"under_\"\n",
    "])]\n",
    "\n",
    "# --- construir X,y sin 'date', sin post-partido y sin mercado ---\n",
    "drop_cols = [TARGET, \"date\"] + [c for c in post_match if c in df.columns] + market_cols\n",
    "X_train = train_df.drop(columns=drop_cols, errors=\"ignore\").replace([np.inf, -np.inf], np.nan)\n",
    "y_train = train_df[TARGET]\n",
    "X_valid = valid_df.drop(columns=drop_cols, errors=\"ignore\").replace([np.inf, -np.inf], np.nan)\n",
    "y_valid = valid_df[TARGET]\n",
    "\n",
    "# Eliminar columnas constantes\n",
    "const_cols = [c for c in X_train.columns if X_train[c].nunique(dropna=False) <= 1]\n",
    "X_train = X_train.drop(columns=const_cols, errors=\"ignore\")\n",
    "X_valid  = X_valid.drop(columns=const_cols, errors=\"ignore\")\n",
    "\n",
    "# Separar tipos\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "naml = naiveautoml.NaiveAutoML(\n",
    "    show_progress=True,             \n",
    ")\n",
    "\n",
    "naml.fit(X_train, y_train, categorical_features=cat_cols, )\n",
    "\n",
    "y_pred = naml.predict(X_valid)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"F1-macro:\", f1_score(y_valid, y_pred, average=\"macro\"))\n",
    "try:\n",
    "    y_proba = naml.predict_proba(X_valid)\n",
    "    print(\"LogLoss:\", log_loss(y_valid, y_proba, labels=naml.classes_))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_valid, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "print(\"\\nCols eliminadas por constantes:\", const_cols)\n",
    "print(\"Núm. numéricas:\", len(num_cols), \" | Núm. categóricas:\", len(cat_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
